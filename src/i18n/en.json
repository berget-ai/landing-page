{
  "modelInference": {
    "title": "Model Inference",
    "description": "Access our extensive collection of powerful open-source models through serverless endpoints. Start building AI applications immediately using the OpenAI API standard.",
    "features": {
      "preTrainedModels": "50+ pre-trained models available",
      "pricing": "Pay-as-you-go pricing",
      "compatibility": "OpenAI API compatibility"
    },
    "codeBlockTitle": "By devs for devs",
    "popularModels": "Popular Models"
  },
  "features": {
    "modelInference": {
      "title": "Model inference",
      "description1": "Serverless inference of powerful open-source models. Access our 50+ models including Llama 3, Mixtral, through serverless endpoints and start building your AI applications using the Open AI API standard.",
      "description2": "It is simple, you can start immediately and you pay as you go.",
      "viewModels": "View Models",
      "learnMore": "Learn More"
    },
    "dedicatedInference": {
      "title": "Dedicated inference for your scaling needs",
      "description": "Host any model, open-source, fine-tuned or one that you trained yourself on our dedicated infrastructure as you scale. Load any model, select GPU instances and deploy your own dedicated inference service and endpoint in a heartbeat."
    },
    "safeCompliantAI": {
      "title": "Safe and compliant AI",
      "description": "With our inference services, your data never leaves the EU, or even our data center. No data - such as prompts and responses - is stored and cannot be accessed by anyone but yourself. This greatly simplifies compliance with EU regulations such as EU AI Act, GDPR, Nis-2 and Dora."
    },
    "productionGradePerformance": {
      "title": "Production-grade performance",
      "description": "Run inference at scale with predictable cost. You pay for the dedicated resources that serves your model, ensuring production-grade latency and throughput for your applications."
    }
  }
}
